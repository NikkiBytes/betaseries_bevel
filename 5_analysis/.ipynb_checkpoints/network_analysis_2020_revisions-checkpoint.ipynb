{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis for BeveL Betaseries \n",
    "\n",
    "Inputs: betaseries files for BeveL participants (n=85) drawn from 4 conditions: choice, reward taste, punishment taste, neutral rinse\n",
    "\n",
    "Analysis workflow is mapped off this paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5429248/\n",
    "\n",
    "\n",
    "### Input Data\n",
    "- One timeseries txt file per participant. Conditions must be separated in unique folder\n",
    "- Need a txt file of the labels for each ROI\n",
    "\n",
    "### Outputs\n",
    "- Circle graph showing thresholded connectivity of each ROI. ROI color denotes modules. \n",
    "- Circle graph of module edge weights. \n",
    "- CSV file with module assignment & nodal metrics for each ROI\n",
    "\n",
    "### Running the notebook\n",
    "The following parts of the code should be changed\n",
    "1. Filepath to timeseries \n",
    "2. Name of circle graph figure\n",
    "3. Module dict to assign to module graph\n",
    "4. Name of module graph figure\n",
    "5. Name of csv file\n",
    "\n",
    "## Note: \n",
    "### Print Statements are commented out to save time, remove comments if desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/vispy/visuals/isocurve.py:22: UserWarning: VisPy is not yet compatible with matplotlib 2.2+\n",
      "  warnings.warn(\"VisPy is not yet compatible with matplotlib 2.2+\")\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import glob\n",
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import pickle\n",
    "import community\n",
    "import statistics\n",
    "import pdb\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "from visbrain.objects import ConnectObj, SceneObj, SourceObj, BrainObj, ColorbarObj\n",
    "from visbrain.io import download_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/Users/jennygilbert/Documents/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corr_network_5(G, corr_direction, min_correlation):\n",
    "\n",
    "    ##Creates a copy of the graph\n",
    "    H = G.copy()\n",
    "    \n",
    "    ##Checks all the edges and removes some based on corr_direction\n",
    "    for stock1, stock2, weight in list(G.edges(data=True)):\n",
    "        ##if we only want to see the positive correlations we then delete the edges with weight smaller than 0        \n",
    "        if corr_direction == \"positive\":\n",
    "            ####it adds a minimum value for correlation. \n",
    "            ####If correlation weaker than the min, then it deletes the edge\n",
    "            if weight[\"weight\"] <0 or weight[\"weight\"] < min_correlation:\n",
    "                H.remove_edge(stock1, stock2)\n",
    "        ##this part runs if the corr_direction is negative and removes edges with weights equal or largen than 0\n",
    "        else:\n",
    "            ####it adds a minimum value for correlation. \n",
    "            ####If correlation weaker than the min, then it deletes the edge\n",
    "            if weight[\"weight\"] >=0 or weight[\"weight\"] > min_correlation:\n",
    "                H.remove_edge(stock1, stock2)\n",
    "    return(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graphs(list_o_data, direction, min_cor):\n",
    "    edge_dict={}\n",
    "    cor_dict={}\n",
    "    FC_dict={}\n",
    "    sd_dict={}\n",
    "    graph_dict={}\n",
    "    partition_dict={}\n",
    "    for key, values in list_o_data.items():\n",
    "            #i=i.set_index(labels.ID)\n",
    "            #i.rename(columns=labels.ID, inplace=True)\n",
    "            ########################################\n",
    "            edge_dict.setdefault(key, []).append(values)\n",
    "            ########################################\n",
    "            cor_matrix = np.asmatrix(values)\n",
    "            x=abs(cor_matrix)\n",
    "            mu=x.mean()\n",
    "            sd=x.std()\n",
    "            ########################################\n",
    "            cor_dict.setdefault(key, []).append(x)\n",
    "            ########################################\n",
    "            FC_dict.setdefault(key, []).append(mu)\n",
    "            sd_dict.setdefault(key, []).append(sd)\n",
    "            ########################################\n",
    "            G = nx.from_numpy_matrix(cor_matrix)\n",
    "            #for i, nlrow in labels.iterrows():\n",
    "                #G.node[i].update(nlrow[0:].to_dict())\n",
    "            ########################################\n",
    "            graph_dict.setdefault(key, []).append(G)\n",
    "            ########################################\n",
    "            partition = community.best_partition(create_corr_network_5(G, direction,min_cor))\n",
    "            ########################################\n",
    "            partition_dict.setdefault(key, []).append(partition)\n",
    "            ########################################\n",
    "    return({'edges':edge_dict, 'correlations':cor_dict, 'mean_FC':FC_dict, 'stdev':sd_dict, 'graphs':graph_dict,'modules':partition_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(G, corr_direction, min_correlation):\n",
    "\n",
    "    ##Creates a copy of the graph\n",
    "    H = G.copy()\n",
    "    \n",
    "    ##Checks all the edges and removes some based on corr_direction\n",
    "    for stock1, stock2, weight in list(G.edges(data=True)):\n",
    "        ##if we only want to see the positive correlations we then delete the edges with weight smaller than 0        \n",
    "        if corr_direction == \"positive\":\n",
    "            ####it adds a minimum value for correlation. \n",
    "            ####If correlation weaker than the min, then it deletes the edge\n",
    "            if weight[\"weight\"] <0 or weight[\"weight\"] < min_correlation:\n",
    "                H.remove_edge(stock1, stock2)\n",
    "        ##this part runs if the corr_direction is negative and removes edges with weights equal or largen than 0\n",
    "        else:\n",
    "            ####it adds a minimum value for correlation. \n",
    "            ####If correlation weaker than the min, then it deletes the edge\n",
    "            if weight[\"weight\"] >=0 or weight[\"weight\"] > min_correlation:\n",
    "                H.remove_edge(stock1, stock2)\n",
    "    return(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the function to combine\n",
    "def make_total_graphs(dict_o_data):\n",
    "    mylist=[]\n",
    "    for key, val_list in dict_o_data.items():\n",
    "        for i in val_list:\n",
    "            cor_matrix = np.asarray(i)\n",
    "            mylist.append(cor_matrix)\n",
    "    x=np.stack(mylist, axis=2)\n",
    "    mu=np.mean(x, axis=(2))\n",
    "    return(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jenny_graph(graph):\n",
    "    edges,weights = zip(*nx.get_edge_attributes(graph, 'weight').items())\n",
    "    nodes, color = zip(*nx.get_node_attributes(graph,'modules').items()) #if your modules are named different change here\n",
    "    nodes, positions = zip(*nx.get_node_attributes(graph,'ROIs').items())\n",
    "    #positions\n",
    "    positions=nx.circular_layout(graph) #this is defining a circluar graph, if you want a different one you change the circular part of this line\n",
    "    \n",
    "    #Figure size\n",
    "    plt.figure(figsize=(40,25))\n",
    "    \n",
    "    \n",
    "    #draws nodes\n",
    "    color = np.array(color)\n",
    "    nColormap=plt.cm.Spectral #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    cM=color.max()\n",
    "    cm=color.min()\n",
    "    y=nx.draw_networkx_nodes(graph,positions, \n",
    "                           node_color=color,\n",
    "                           node_size=1000,\n",
    "                           alpha=1, \n",
    "                           cmap= nColormap,\n",
    "                           vmin=cm ,vmax=cM)\n",
    "\n",
    "    #Styling for labels\n",
    "    nx.draw_networkx_labels(graph, positions, font_size=10, \n",
    "                            font_family='sans-serif', fontweight = 'bold')\n",
    "    \n",
    "    \n",
    "    #draw edges\n",
    "    weights=np.array(weights)\n",
    "    eColormap=plt.cm.bwr #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    wt=weights*5\n",
    "    M=wt.max()\n",
    "    m=wt.min()\n",
    "    x=nx.draw_networkx_edges(graph, positions, edge_list=edges, style='solid', width = wt, edge_color = wt,\n",
    "                           cmap=eColormap,\n",
    "                           edge_vmin=m,\n",
    "                           edge_vmax=M)\n",
    "    \n",
    "    #format the colorbar\n",
    "    node_bar=plt.colorbar(y)\n",
    "    edge_bar=plt.colorbar(x)\n",
    "\n",
    "    node_bar.set_label('Modularity',fontsize = 25)\n",
    "    edge_bar.set_label('Strength of edge weight',fontsize = 25)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Modularity and Edge Weights of Average Graph\", fontsize = 30)\n",
    "#plt.savefig(os.path.join(basepath,\"betaseries_bevel/5_analysis/modularity_circle_reward.png\", format=\"PNG\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response to CHOICE\n",
    "\n",
    "## Load in the data\n",
    "\n",
    "### Find the path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the path to data\n",
    "file_list = glob.glob(os.path.join(basepath,'betaseries_bevel/4_combine_timeseries/choice/*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dictionary to read in the files to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting the ditionary\n",
    "my_dict={}\n",
    "for item in file_list:\n",
    "    name=item.split('/')[7].split('.')[0]\n",
    "    #print(name)\n",
    "    my_dict.setdefault(name, []).append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from the dictionary into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the data dictionary\n",
    "data_dict={}\n",
    "for key, value in my_dict.items():\n",
    "    for i in value:\n",
    "        data_dict.setdefault(key, []).append(pd.read_csv(i, sep='\\t' ,header=None,index_col=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dictionary with correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the correlation dictionary\n",
    "cor_dict={}\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    value[0]\n",
    "    #pdb.set_trace()\n",
    "    cor_matrix = value[0].corr()\n",
    "    cor_dict[key] = cor_matrix   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Dictionary with ROI Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This points to a txt file with the ROI names in a list separated by commas\n",
    "path = os.path.join(basepath,'betaseries_bevel/5_analysis/labels.txt')\n",
    "df_label = pd.read_csv(path, sep=',')\n",
    "\n",
    "#df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "n=0\n",
    "for item in df_label:\n",
    "    labels_dict[n]=item\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to make a graph object BY SUBJECT\n",
    "This will return:\n",
    "- The edges (noramlized R correlation matrix, in pandas dataframe)\n",
    "- The correlations (absolute value of the edges in a numpy dataframe)\n",
    "- The mean_FC (the mean functional connectivity per subject/run)\n",
    "- The graphs (this will contain the raw graph object G as well as the the partion values from the modularity calculation)\n",
    "- The modules (communitites in the network at the participant level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "GRAPHS = make_graphs(cor_dict, \"positive\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into BMI Subsamples\n",
    "\n",
    "### Groups: \n",
    "- HW: BMI < 25.0 (n = 52) \n",
    "- OB: BMI > 25.0 (n = 33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list with the subejcts in each group\n",
    "hw_list = {'sub-001_choice',\n",
    "'sub-002_choice',\n",
    "'sub-004_choice',\n",
    "'sub-005_choice',\n",
    "'sub-006_choice',\n",
    "'sub-007_choice',\n",
    "'sub-009_choice',\n",
    "'sub-011_choice',\n",
    "'sub-014_choice',\n",
    "'sub-015_choice',\n",
    "'sub-016_choice',\n",
    "'sub-017_choice',\n",
    "'sub-018_choice',\n",
    "'sub-019_choice',\n",
    "'sub-021_choice',\n",
    "'sub-024_choice',\n",
    "'sub-025_choice',\n",
    "'sub-026_choice',\n",
    "'sub-029_choice',\n",
    "'sub-030_choice',\n",
    "'sub-031_choice',\n",
    "'sub-032_choice',\n",
    "'sub-036_choice',\n",
    "'sub-038_choice',\n",
    "'sub-040_choice',\n",
    "'sub-045_choice',\n",
    "'sub-047_choice',\n",
    "'sub-048_choice',\n",
    "'sub-050_choice',\n",
    "'sub-052_choice',\n",
    "'sub-053_choice',\n",
    "'sub-054_choice',\n",
    "'sub-055_choice',\n",
    "'sub-056_choice',\n",
    "'sub-058_choice',\n",
    "'sub-059_choice',\n",
    "'sub-060_choice',\n",
    "'sub-061_choice',\n",
    "'sub-062_choice',\n",
    "'sub-066_choice',\n",
    "'sub-068_choice',\n",
    "'sub-069_choice',\n",
    "'sub-070_choice',\n",
    "'sub-072_choice',\n",
    "'sub-073_choice',\n",
    "'sub-074_choice',\n",
    "'sub-075_choice',\n",
    "'sub-082_choice',\n",
    "'sub-084_choice',\n",
    "'sub-085_choice',\n",
    "'sub-087_choice',\n",
    "'sub-088_choice',}\n",
    "\n",
    "ob_list = {'sub-003_choice',\n",
    "'sub-010_choice',\n",
    "'sub-020_choice',\n",
    "'sub-022_choice',\n",
    "'sub-044_choice',\n",
    "'sub-067_choice',\n",
    "'sub-083_choice',\n",
    "'sub-012_choice',\n",
    "'sub-013_choice',\n",
    "'sub-027_choice',\n",
    "'sub-028_choice',\n",
    "'sub-033_choice',\n",
    "'sub-034_choice',\n",
    "'sub-035_choice',\n",
    "'sub-037_choice',\n",
    "'sub-039_choice',\n",
    "'sub-041_choice',\n",
    "'sub-042_choice',\n",
    "'sub-043_choice',\n",
    "'sub-046_choice',\n",
    "'sub-057_choice',\n",
    "'sub-063_choice',\n",
    "'sub-064_choice',\n",
    "'sub-071_choice',\n",
    "'sub-076_choice',\n",
    "'sub-077_choice',\n",
    "'sub-078_choice',\n",
    "'sub-079_choice',\n",
    "'sub-080_choice',\n",
    "'sub-081_choice',\n",
    "'sub-086_choice',\n",
    "'sub-089_choice',\n",
    "'sub-090_choice',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dictionary by the list items\n",
    "hw_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in hw_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dictionary by the list items\n",
    "ob_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in ob_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make the mean graph with correlations\n",
    "mean_hw_graph = make_total_graphs(hw_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the mean graph with correlations\n",
    "mean_ob_graph = make_total_graphs(ob_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30272478711538886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to make sure this worked \n",
    "print(mean_hw_graph.shape)\n",
    "\n",
    "#Convert the graph to a numpy matrix so it can be recognized by networkX\n",
    "mean_hw_graph_mat = np.matrix(mean_hw_graph)\n",
    "\n",
    "#Check the mean correlation to use to threshold later\n",
    "mean_hw_graph_mat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to a numpy object\n",
    "mean_ob_graph_mat = np.matrix(mean_ob_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to a matrix\n",
    "mean_HW_G = nx.from_numpy_matrix(mean_hw_graph_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to a matrix\n",
    "mean_OB_G = nx.from_numpy_matrix(mean_ob_graph_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the community structure\n",
    "partition_HW = community.best_partition(mean_HW_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the modules and ROI labels to the graph\n",
    "nx.set_node_attributes(mean_HW_G, partition_HW, 'modules')\n",
    "nx.set_node_attributes(mean_HW_G, labels_dict, 'ROIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the community structure\n",
    "partition_OB = community.best_partition(mean_OB_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the modules and ROI labels to the graph\n",
    "nx.set_node_attributes(mean_OB_G, partition_OB, 'modules')\n",
    "nx.set_node_attributes(mean_OB_G, labels_dict, 'ROIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold the graph for visualization\n",
    "thresh_HW_G = threshold(mean_HW_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold the graph for visualization\n",
    "thresh_OB_G = threshold(mean_OB_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to visualize thresholded graph with modules in colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_HW_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_OB_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make a dictionary with both partitions\n",
    "ds = [partition_HW, partition_OB]\n",
    "d = {}\n",
    "for k in partition_HW.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (0, 2),\n",
       " 5: (2, 2),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (3, 3),\n",
       " 9: (3, 3),\n",
       " 10: (2, 2),\n",
       " 11: (2, 2),\n",
       " 12: (4, 4),\n",
       " 13: (4, 4),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (5, 5),\n",
       " 19: (5, 5),\n",
       " 20: (6, 6),\n",
       " 21: (6, 6),\n",
       " 22: (7, 7),\n",
       " 23: (7, 7),\n",
       " 24: (3, 3),\n",
       " 25: (3, 3),\n",
       " 26: (7, 7),\n",
       " 27: (7, 7)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6955665770524795"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the NMI to quantify how different the two partitions are. \n",
    "partition_HW_list = []\n",
    "for value in partition_HW.values():\n",
    "    partition_HW_list.append(partition_HW[value])\n",
    "\n",
    "partition_OB_list = []\n",
    "for value in partition_OB.values():\n",
    "    partition_OB_list.append(partition_OB[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_HW_list, partition_OB_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Which Edges are Different in HW and OB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([(1, 4), (1, 21), (1, 25), (2, 25), (3, 18), (6, 9), (6, 21), (10, 14), (16, 25), (18, 21), (18, 22)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the edges in HW but not OB\n",
    "diffHW_GRAPH = nx.difference(thresh_HW_G, thresh_OB_G)\n",
    "nx.edges(diffHW_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([(0, 19), (0, 21), (2, 10), (2, 11), (2, 12), (2, 13), (2, 15), (3, 12), (4, 11), (4, 15), (4, 26), (5, 6), (5, 13), (5, 15), (6, 14), (6, 17), (6, 18), (6, 19), (6, 26), (7, 8), (7, 25), (8, 12), (8, 19), (10, 12), (10, 17), (11, 12), (11, 14), (11, 17), (12, 15), (12, 16), (12, 17), (12, 24), (13, 15), (13, 16), (13, 17), (13, 25), (15, 17), (15, 22), (15, 24), (16, 18), (16, 19), (18, 25), (18, 27), (19, 22), (19, 23), (24, 26)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the edges in OB but not HW\n",
    "diffOB_GRAPH = nx.difference(thresh_OB_G,thresh_HW_G)\n",
    "nx.edges(diffOB_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into Learner Subsamples\n",
    "### Groups:\n",
    "- Learner: overall posttest accuracy > 50% (n = 45) \n",
    "- Nonlearner: overall posttest accuracy < 50% (n = 40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_list = {'sub-001_choice',\n",
    "'sub-002_choice',\n",
    "'sub-004_choice',\n",
    "'sub-006_choice',\n",
    "'sub-009_choice',\n",
    "'sub-011_choice',\n",
    "'sub-015_choice',\n",
    "'sub-017_choice',\n",
    "'sub-024_choice',\n",
    "'sub-026_choice',\n",
    "'sub-029_choice',\n",
    "'sub-031_choice',\n",
    "'sub-036_choice',\n",
    "'sub-038_choice',\n",
    "'sub-045_choice',\n",
    "'sub-047_choice',\n",
    "'sub-048_choice',\n",
    "'sub-050_choice',\n",
    "'sub-056_choice',\n",
    "'sub-058_choice',\n",
    "'sub-060_choice',\n",
    "'sub-061_choice',\n",
    "'sub-062_choice',\n",
    "'sub-068_choice',\n",
    "'sub-069_choice',\n",
    "'sub-070_choice',\n",
    "'sub-073_choice',\n",
    "'sub-075_choice',\n",
    "'sub-084_choice',\n",
    "'sub-085_choice',\n",
    "'sub-088_choice',\n",
    "'sub-003_choice',\n",
    "'sub-010_choice',\n",
    "'sub-020_choice',\n",
    "'sub-022_choice',\n",
    "'sub-013_choice',\n",
    "'sub-027_choice',\n",
    "'sub-037_choice',\n",
    "'sub-041_choice',\n",
    "'sub-043_choice',\n",
    "'sub-064_choice',\n",
    "'sub-071_choice',\n",
    "'sub-079_choice',\n",
    "'sub-086_choice',\n",
    "'sub-089_choice',}\n",
    "\n",
    "nolearn_list = {'sub-005_choice',\n",
    "'sub-007_choice',\n",
    "'sub-014_choice',\n",
    "'sub-016_choice',\n",
    "'sub-018_choice',\n",
    "'sub-019_choice',\n",
    "'sub-021_choice',\n",
    "'sub-025_choice',\n",
    "'sub-030_choice',\n",
    "'sub-032_choice',\n",
    "'sub-040_choice',\n",
    "'sub-052_choice',\n",
    "'sub-053_choice',\n",
    "'sub-054_choice',\n",
    "'sub-055_choice',\n",
    "'sub-059_choice',\n",
    "'sub-066_choice',\n",
    "'sub-072_choice',\n",
    "'sub-074_choice',\n",
    "'sub-082_choice',\n",
    "'sub-087_choice',\n",
    "'sub-044_choice',\n",
    "'sub-067_choice',\n",
    "'sub-083_choice',\n",
    "'sub-028_choice',\n",
    "'sub-033_choice',\n",
    "'sub-034_choice',\n",
    "'sub-035_choice',\n",
    "'sub-039_choice',\n",
    "'sub-042_choice',\n",
    "'sub-046_choice',\n",
    "'sub-057_choice',\n",
    "'sub-063_choice',\n",
    "'sub-076_choice',\n",
    "'sub-077_choice',\n",
    "'sub-078_choice',\n",
    "'sub-080_choice',\n",
    "'sub-081_choice',\n",
    "'sub-090_choice',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in learn_list}\n",
    "nolearn_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in nolearn_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_learn_graph = make_total_graphs(learn_corr_dict)\n",
    "mean_nolearn_graph = make_total_graphs(nolearn_corr_dict)\n",
    "\n",
    "mean_learn_graph_mat = np.matrix(mean_learn_graph)\n",
    "mean_nolearn_graph_mat = np.matrix(mean_nolearn_graph)\n",
    "\n",
    "mean_learn_G = nx.from_numpy_matrix(mean_learn_graph_mat)\n",
    "mean_nolearn_G = nx.from_numpy_matrix(mean_nolearn_graph_mat)\n",
    "\n",
    "partition_l = community.best_partition(mean_learn_G)\n",
    "nx.set_node_attributes(mean_learn_G, partition_l, 'modules')\n",
    "nx.set_node_attributes(mean_learn_G, labels_dict, 'ROIs')\n",
    "\n",
    "partition_nl = community.best_partition(mean_nolearn_G)\n",
    "nx.set_node_attributes(mean_nolearn_G, partition_nl, 'modules')\n",
    "nx.set_node_attributes(mean_nolearn_G, labels_dict, 'ROIs')\n",
    "\n",
    "thresh_learn_G = threshold(mean_learn_G, 'positive', 0.3)\n",
    "thresh_nolearn_G = threshold(mean_nolearn_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_learn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_nolearn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [partition_l, partition_nl]\n",
    "d = {}\n",
    "for k in partition_l.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (0, 2),\n",
       " 5: (2, 2),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (3, 3),\n",
       " 9: (3, 3),\n",
       " 10: (2, 2),\n",
       " 11: (2, 2),\n",
       " 12: (4, 4),\n",
       " 13: (4, 4),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (5, 5),\n",
       " 19: (5, 6),\n",
       " 20: (6, 5),\n",
       " 21: (6, 5),\n",
       " 22: (7, 1),\n",
       " 23: (7, 1),\n",
       " 24: (3, 3),\n",
       " 25: (3, 3),\n",
       " 26: (1, 6),\n",
       " 27: (1, 6)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5585026269033441"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_l_list = []\n",
    "for value in partition_l.values():\n",
    "    partition_l_list.append(partition_l[value])\n",
    "\n",
    "partition_nl_list = []\n",
    "for value in partition_nl.values():\n",
    "    partition_nl_list.append(partition_nl[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_l_list, partition_nl_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into by Sex\n",
    "### Groups:\n",
    "- Male (n = 42) \n",
    "- Female (n = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list ={'sub-001_choice',\n",
    "'sub-015_choice',\n",
    "'sub-038_choice',\n",
    "'sub-045_choice',\n",
    "'sub-047_choice',\n",
    "'sub-048_choice',\n",
    "'sub-050_choice',\n",
    "'sub-056_choice',\n",
    "'sub-058_choice',\n",
    "'sub-060_choice',\n",
    "'sub-061_choice',\n",
    "'sub-062_choice',\n",
    "'sub-068_choice',\n",
    "'sub-075_choice',\n",
    "'sub-084_choice',\n",
    "'sub-085_choice',\n",
    "'sub-088_choice',\n",
    "'sub-022_choice',\n",
    "'sub-037_choice',\n",
    "'sub-043_choice',\n",
    "'sub-064_choice',\n",
    "'sub-079_choice',\n",
    "'sub-014_choice',\n",
    "'sub-016_choice',\n",
    "'sub-019_choice',\n",
    "'sub-053_choice',\n",
    "'sub-054_choice',\n",
    "'sub-055_choice',\n",
    "'sub-059_choice',\n",
    "'sub-074_choice',\n",
    "'sub-082_choice',\n",
    "'sub-044_choice',\n",
    "'sub-028_choice',\n",
    "'sub-033_choice',\n",
    "'sub-034_choice',\n",
    "'sub-035_choice',\n",
    "'sub-042_choice',\n",
    "'sub-046_choice',\n",
    "'sub-057_choice',\n",
    "'sub-076_choice',\n",
    "'sub-080_choice',\n",
    "'sub-090_choice',}\n",
    "f_list = {'sub-002_choice',\n",
    "'sub-004_choice',\n",
    "'sub-006_choice',\n",
    "'sub-009_choice',\n",
    "'sub-011_choice',\n",
    "'sub-017_choice',\n",
    "'sub-024_choice',\n",
    "'sub-026_choice',\n",
    "'sub-029_choice',\n",
    "'sub-031_choice',\n",
    "'sub-036_choice',\n",
    "'sub-069_choice',\n",
    "'sub-070_choice',\n",
    "'sub-073_choice',\n",
    "'sub-003_choice',\n",
    "'sub-010_choice',\n",
    "'sub-020_choice',\n",
    "'sub-013_choice',\n",
    "'sub-027_choice',\n",
    "'sub-041_choice',\n",
    "'sub-071_choice',\n",
    "'sub-086_choice',\n",
    "'sub-089_choice',\n",
    "'sub-012_choice',\n",
    "'sub-005_choice',\n",
    "'sub-007_choice',\n",
    "'sub-018_choice',\n",
    "'sub-021_choice',\n",
    "'sub-025_choice',\n",
    "'sub-030_choice',\n",
    "'sub-032_choice',\n",
    "'sub-040_choice',\n",
    "'sub-052_choice',\n",
    "'sub-066_choice',\n",
    "'sub-072_choice',\n",
    "'sub-087_choice',\n",
    "'sub-067_choice',\n",
    "'sub-083_choice',\n",
    "'sub-039_choice',\n",
    "'sub-063_choice',\n",
    "'sub-077_choice',\n",
    "'sub-078_choice',\n",
    "'sub-081_choice',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in m_list}\n",
    "f_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in f_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_m_graph = make_total_graphs(m_corr_dict)\n",
    "mean_f_graph = make_total_graphs(f_corr_dict)\n",
    "\n",
    "mean_m_graph_mat = np.matrix(mean_m_graph)\n",
    "mean_f_graph_mat = np.matrix(mean_f_graph)\n",
    "\n",
    "mean_m_G = nx.from_numpy_matrix(mean_m_graph_mat)\n",
    "mean_f_G = nx.from_numpy_matrix(mean_f_graph_mat)\n",
    "\n",
    "partition_m = community.best_partition(mean_m_G)\n",
    "nx.set_node_attributes(mean_m_G, partition_m, 'modules')\n",
    "nx.set_node_attributes(mean_m_G, labels_dict, 'ROIs')\n",
    "\n",
    "partition_f = community.best_partition(mean_f_G)\n",
    "nx.set_node_attributes(mean_f_G, partition_f, 'modules')\n",
    "nx.set_node_attributes(mean_f_G, labels_dict, 'ROIs')\n",
    "\n",
    "thresh_m_G = threshold(mean_m_G, 'positive', 0.3)\n",
    "thresh_f_G = threshold(mean_f_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_m_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_f_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [partition_m, partition_f]\n",
    "d = {}\n",
    "for k in partition_m.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (0, 2),\n",
       " 5: (2, 2),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (3, 3),\n",
       " 9: (3, 3),\n",
       " 10: (2, 2),\n",
       " 11: (2, 2),\n",
       " 12: (4, 4),\n",
       " 13: (4, 4),\n",
       " 14: (5, 2),\n",
       " 15: (5, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (6, 5),\n",
       " 19: (6, 6),\n",
       " 20: (7, 5),\n",
       " 21: (7, 5),\n",
       " 22: (8, 7),\n",
       " 23: (8, 7),\n",
       " 24: (3, 3),\n",
       " 25: (3, 3),\n",
       " 26: (1, 6),\n",
       " 27: (1, 6)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525575621852539"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_m_list = []\n",
    "for value in partition_m.values():\n",
    "    partition_m_list.append(partition_m[value])\n",
    "\n",
    "partition_f_list = []\n",
    "for value in partition_f.values():\n",
    "    partition_f_list.append(partition_f[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_m_list, partition_f_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Subsample to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list ={'sub-083_choice',\n",
    "'sub-031_choice',\n",
    "'sub-061_choice',\n",
    "'sub-070_choice',\n",
    "'sub-072_choice',\n",
    "'sub-090_choice',\n",
    "'sub-069_choice',\n",
    "'sub-060_choice',\n",
    "'sub-041_choice',\n",
    "'sub-076_choice',\n",
    "'sub-088_choice',\n",
    "'sub-019_choice',\n",
    "'sub-037_choice',\n",
    "'sub-058_choice',\n",
    "'sub-042_choice',\n",
    "'sub-056_choice',\n",
    "'sub-062_choice',\n",
    "'sub-074_choice',\n",
    "'sub-075_choice',\n",
    "'sub-085_choice',\n",
    "'sub-045_choice',\n",
    "'sub-047_choice',\n",
    "'sub-001_choice',\n",
    "'sub-052_choice',\n",
    "'sub-016_choice',\n",
    "'sub-027_choice',\n",
    "'sub-079_choice',\n",
    "'sub-035_choice',\n",
    "'sub-086_choice',\n",
    "'sub-084_choice',\n",
    "'sub-055_choice',\n",
    "'sub-010_choice',\n",
    "'sub-063_choice',\n",
    "'sub-011_choice',\n",
    "'sub-080_choice',\n",
    "'sub-036_choice',\n",
    "'sub-082_choice',\n",
    "'sub-032_choice',\n",
    "'sub-067_choice',\n",
    "'sub-006_choice',\n",
    "'sub-012_choice',\n",
    "'sub-033_choice',\n",
    "'sub-078_choice'}\n",
    "b_list = {'sub-004_choice',\n",
    "'sub-020_choice',\n",
    "'sub-034_choice',\n",
    "'sub-050_choice',\n",
    "'sub-066_choice',\n",
    "'sub-038_choice',\n",
    "'sub-029_choice',\n",
    "'sub-081_choice',\n",
    "'sub-025_choice',\n",
    "'sub-024_choice',\n",
    "'sub-030_choice',\n",
    "'sub-040_choice',\n",
    "'sub-068_choice',\n",
    "'sub-039_choice',\n",
    "'sub-017_choice',\n",
    "'sub-007_choice',\n",
    "'sub-073_choice',\n",
    "'sub-064_choice',\n",
    "'sub-043_choice',\n",
    "'sub-028_choice',\n",
    "'sub-015_choice',\n",
    "'sub-046_choice',\n",
    "'sub-054_choice',\n",
    "'sub-057_choice',\n",
    "'sub-005_choice',\n",
    "'sub-018_choice',\n",
    "'sub-071_choice',\n",
    "'sub-077_choice',\n",
    "'sub-089_choice',\n",
    "'sub-053_choice',\n",
    "'sub-021_choice',\n",
    "'sub-022_choice',\n",
    "'sub-013_choice',\n",
    "'sub-059_choice',\n",
    "'sub-044_choice',\n",
    "'sub-009_choice',\n",
    "'sub-014_choice',\n",
    "'sub-087_choice',\n",
    "'sub-003_choice',\n",
    "'sub-048_choice',\n",
    "'sub-026_choice',\n",
    "'sub-002_choice'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in a_list}\n",
    "b_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in b_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_a_graph = make_total_graphs(a_corr_dict)\n",
    "mean_b_graph = make_total_graphs(b_corr_dict)\n",
    "\n",
    "mean_a_graph_mat = np.matrix(mean_a_graph)\n",
    "mean_b_graph_mat = np.matrix(mean_b_graph)\n",
    "\n",
    "mean_a_G = nx.from_numpy_matrix(mean_a_graph_mat)\n",
    "mean_b_G = nx.from_numpy_matrix(mean_b_graph_mat)\n",
    "\n",
    "partition_a = community.best_partition(mean_a_G)\n",
    "nx.set_node_attributes(mean_a_G, partition_a, 'modules')\n",
    "nx.set_node_attributes(mean_a_G, labels_dict, 'ROIs')\n",
    "\n",
    "partition_b = community.best_partition(mean_b_G)\n",
    "nx.set_node_attributes(mean_b_G, partition_b, 'modules')\n",
    "nx.set_node_attributes(mean_b_G, labels_dict, 'ROIs')\n",
    "\n",
    "thresh_a_G = threshold(mean_a_G, 'positive', 0.3)\n",
    "thresh_b_G = threshold(mean_b_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [partition_a, partition_b]\n",
    "d = {}\n",
    "for k in partition_m.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (0, 0),\n",
       " 5: (2, 2),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (3, 3),\n",
       " 9: (3, 3),\n",
       " 10: (2, 2),\n",
       " 11: (2, 2),\n",
       " 12: (4, 4),\n",
       " 13: (4, 4),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (5, 5),\n",
       " 19: (5, 5),\n",
       " 20: (6, 6),\n",
       " 21: (6, 6),\n",
       " 22: (7, 1),\n",
       " 23: (7, 1),\n",
       " 24: (3, 3),\n",
       " 25: (3, 3),\n",
       " 26: (8, 1),\n",
       " 27: (8, 1)}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response to REWARD\n",
    "\n",
    "## Load in the data\n",
    "\n",
    "### Find the path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the path to data\n",
    "file_list = glob.glob(os.path.join(basepath,'betaseries_bevel/4_combine_timeseries/reward/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting the ditionary\n",
    "my_dict={}\n",
    "for item in file_list:\n",
    "    name=item.split('/')[7].split('.')[0]\n",
    "    #print(name)\n",
    "    my_dict.setdefault(name, []).append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the data dictionary\n",
    "data_dict={}\n",
    "for key, value in my_dict.items():\n",
    "    for i in value:\n",
    "        data_dict.setdefault(key, []).append(pd.read_csv(i, sep='\\t' ,header=None,index_col=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the correlation dictionary\n",
    "cor_dict={}\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    value[0]\n",
    "    #pdb.set_trace()\n",
    "    cor_matrix = value[0].corr()\n",
    "    cor_dict[key] = cor_matrix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "GRAPHS = make_graphs(cor_dict, \"positive\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into BMI Subsamples\n",
    "\n",
    "### Groups: \n",
    "- HW: BMI < 25.0\n",
    "- OB: BMI > 25.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_list = {'sub-001_reward',\n",
    "'sub-002_reward',\n",
    "'sub-004_reward',\n",
    "'sub-005_reward',\n",
    "'sub-006_reward',\n",
    "'sub-007_reward',\n",
    "'sub-009_reward',\n",
    "'sub-011_reward',\n",
    "'sub-014_reward',\n",
    "'sub-015_reward',\n",
    "'sub-016_reward',\n",
    "'sub-017_reward',\n",
    "'sub-018_reward',\n",
    "'sub-019_reward',\n",
    "'sub-021_reward',\n",
    "'sub-024_reward',\n",
    "'sub-025_reward',\n",
    "'sub-026_reward',\n",
    "'sub-029_reward',\n",
    "'sub-030_reward',\n",
    "'sub-031_reward',\n",
    "'sub-032_reward',\n",
    "'sub-036_reward',\n",
    "'sub-038_reward',\n",
    "'sub-040_reward',\n",
    "'sub-045_reward',\n",
    "'sub-047_reward',\n",
    "'sub-048_reward',\n",
    "'sub-050_reward',\n",
    "'sub-052_reward',\n",
    "'sub-053_reward',\n",
    "'sub-054_reward',\n",
    "'sub-055_reward',\n",
    "'sub-056_reward',\n",
    "'sub-058_reward',\n",
    "'sub-059_reward',\n",
    "'sub-060_reward',\n",
    "'sub-061_reward',\n",
    "'sub-062_reward',\n",
    "'sub-066_reward',\n",
    "'sub-068_reward',\n",
    "'sub-069_reward',\n",
    "'sub-070_reward',\n",
    "'sub-072_reward',\n",
    "'sub-073_reward',\n",
    "'sub-074_reward',\n",
    "'sub-075_reward',\n",
    "'sub-082_reward',\n",
    "'sub-084_reward',\n",
    "'sub-085_reward',\n",
    "'sub-087_reward',\n",
    "'sub-088_reward',}\n",
    "\n",
    "ob_list = {'sub-003_reward',\n",
    "'sub-010_reward',\n",
    "'sub-020_reward',\n",
    "'sub-022_reward',\n",
    "'sub-044_reward',\n",
    "'sub-067_reward',\n",
    "'sub-083_reward',\n",
    "'sub-012_reward',\n",
    "'sub-013_reward',\n",
    "'sub-027_reward',\n",
    "'sub-028_reward',\n",
    "'sub-033_reward',\n",
    "'sub-034_reward',\n",
    "'sub-035_reward',\n",
    "'sub-037_reward',\n",
    "'sub-039_reward',\n",
    "'sub-041_reward',\n",
    "'sub-042_reward',\n",
    "'sub-043_reward',\n",
    "'sub-046_reward',\n",
    "'sub-057_reward',\n",
    "'sub-063_reward',\n",
    "'sub-064_reward',\n",
    "'sub-071_reward',\n",
    "'sub-076_reward',\n",
    "'sub-077_reward',\n",
    "'sub-078_reward',\n",
    "'sub-079_reward',\n",
    "'sub-080_reward',\n",
    "'sub-081_reward',\n",
    "'sub-086_reward',\n",
    "'sub-089_reward',\n",
    "'sub-090_reward',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in hw_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in ob_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make the mean graph with correlations\n",
    "mean_hw_graph = make_total_graphs(hw_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ob_graph = make_total_graphs(ob_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2892331776137158"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to make sure this worked \n",
    "print(mean_hw_graph.shape)\n",
    "\n",
    "#Convert the graph to a numpy matrix so it can be recognized by networkX\n",
    "mean_hw_graph_mat = np.matrix(mean_hw_graph)\n",
    "\n",
    "#Check the mean correlation to use to threshold later\n",
    "mean_hw_graph_mat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ob_graph_mat = np.matrix(mean_ob_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_HW_G = nx.from_numpy_matrix(mean_hw_graph_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_OB_G = nx.from_numpy_matrix(mean_ob_graph_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_HW = community.best_partition(mean_HW_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the modules and ROI labels to the graph\n",
    "nx.set_node_attributes(mean_HW_G, partition_HW, 'modules')\n",
    "nx.set_node_attributes(mean_HW_G, labels_dict, 'ROIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_OB = community.best_partition(mean_OB_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(mean_OB_G, partition_OB, 'modules')\n",
    "nx.set_node_attributes(mean_OB_G, labels_dict, 'ROIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_HW_G = threshold(mean_HW_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_OB_G = threshold(mean_OB_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_HW_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_OB_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = [partition_HW, partition_OB]\n",
    "d = {}\n",
    "for k in partition_HW.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (2, 2),\n",
       " 5: (3, 2),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (4, 3),\n",
       " 9: (4, 3),\n",
       " 10: (3, 2),\n",
       " 11: (3, 2),\n",
       " 12: (5, 4),\n",
       " 13: (5, 4),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (6, 5),\n",
       " 19: (6, 5),\n",
       " 20: (7, 6),\n",
       " 21: (7, 6),\n",
       " 22: (8, 5),\n",
       " 23: (8, 5),\n",
       " 24: (4, 3),\n",
       " 25: (4, 3),\n",
       " 26: (8, 5),\n",
       " 27: (8, 5)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into Learner Subsamples\n",
    "### Groups:\n",
    "- Learner: overall posttest accuracy > 50%\n",
    "- Nonlearner: overall posttest accuracy < 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_list = {'sub-001_reward',\n",
    "'sub-002_reward',\n",
    "'sub-004_reward',\n",
    "'sub-006_reward',\n",
    "'sub-009_reward',\n",
    "'sub-011_reward',\n",
    "'sub-015_reward',\n",
    "'sub-017_reward',\n",
    "'sub-024_reward',\n",
    "'sub-026_reward',\n",
    "'sub-029_reward',\n",
    "'sub-031_reward',\n",
    "'sub-036_reward',\n",
    "'sub-038_reward',\n",
    "'sub-045_reward',\n",
    "'sub-047_reward',\n",
    "'sub-048_reward',\n",
    "'sub-050_reward',\n",
    "'sub-056_reward',\n",
    "'sub-058_reward',\n",
    "'sub-060_reward',\n",
    "'sub-061_reward',\n",
    "'sub-062_reward',\n",
    "'sub-068_reward',\n",
    "'sub-069_reward',\n",
    "'sub-070_reward',\n",
    "'sub-073_reward',\n",
    "'sub-075_reward',\n",
    "'sub-084_reward',\n",
    "'sub-085_reward',\n",
    "'sub-088_reward',\n",
    "'sub-003_reward',\n",
    "'sub-010_reward',\n",
    "'sub-020_reward',\n",
    "'sub-022_reward',\n",
    "'sub-013_reward',\n",
    "'sub-027_reward',\n",
    "'sub-037_reward',\n",
    "'sub-041_reward',\n",
    "'sub-043_reward',\n",
    "'sub-064_reward',\n",
    "'sub-071_reward',\n",
    "'sub-079_reward',\n",
    "'sub-086_reward',\n",
    "'sub-089_reward',}\n",
    "\n",
    "nolearn_list = {'sub-005_reward',\n",
    "'sub-007_reward',\n",
    "'sub-014_reward',\n",
    "'sub-016_reward',\n",
    "'sub-018_reward',\n",
    "'sub-019_reward',\n",
    "'sub-021_reward',\n",
    "'sub-025_reward',\n",
    "'sub-030_reward',\n",
    "'sub-032_reward',\n",
    "'sub-040_reward',\n",
    "'sub-052_reward',\n",
    "'sub-053_reward',\n",
    "'sub-054_reward',\n",
    "'sub-055_reward',\n",
    "'sub-059_reward',\n",
    "'sub-066_reward',\n",
    "'sub-072_reward',\n",
    "'sub-074_reward',\n",
    "'sub-082_reward',\n",
    "'sub-087_reward',\n",
    "'sub-044_reward',\n",
    "'sub-067_reward',\n",
    "'sub-083_reward',\n",
    "'sub-028_reward',\n",
    "'sub-033_reward',\n",
    "'sub-034_reward',\n",
    "'sub-035_reward',\n",
    "'sub-039_reward',\n",
    "'sub-042_reward',\n",
    "'sub-046_reward',\n",
    "'sub-057_reward',\n",
    "'sub-063_reward',\n",
    "'sub-076_reward',\n",
    "'sub-077_reward',\n",
    "'sub-078_reward',\n",
    "'sub-080_reward',\n",
    "'sub-081_reward',\n",
    "'sub-090_reward',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in learn_list}\n",
    "nolearn_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in nolearn_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_learn_graph = make_total_graphs(learn_corr_dict)\n",
    "mean_nolearn_graph = make_total_graphs(nolearn_corr_dict)\n",
    "\n",
    "mean_learn_graph_mat = np.matrix(mean_learn_graph)\n",
    "mean_nolearn_graph_mat = np.matrix(mean_nolearn_graph)\n",
    "\n",
    "mean_learn_G = nx.from_numpy_matrix(mean_learn_graph_mat)\n",
    "mean_nolearn_G = nx.from_numpy_matrix(mean_nolearn_graph_mat)\n",
    "\n",
    "partition_l = community.best_partition(mean_learn_G)\n",
    "nx.set_node_attributes(mean_learn_G, partition_l, 'modules')\n",
    "nx.set_node_attributes(mean_learn_G, labels_dict, 'ROIs')\n",
    "\n",
    "partition_nl = community.best_partition(mean_nolearn_G)\n",
    "nx.set_node_attributes(mean_nolearn_G, partition_nl, 'modules')\n",
    "nx.set_node_attributes(mean_nolearn_G, labels_dict, 'ROIs')\n",
    "\n",
    "thresh_learn_G = threshold(mean_learn_G, 'positive', 0.3)\n",
    "thresh_nolearn_G = threshold(mean_nolearn_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_learn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_nolearn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [partition_l, partition_nl]\n",
    "d = {}\n",
    "for k in partition_l.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (2, 2),\n",
       " 5: (3, 3),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (4, 4),\n",
       " 9: (4, 4),\n",
       " 10: (3, 3),\n",
       " 11: (3, 3),\n",
       " 12: (5, 3),\n",
       " 13: (5, 3),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (6, 5),\n",
       " 19: (6, 5),\n",
       " 20: (7, 6),\n",
       " 21: (7, 6),\n",
       " 22: (8, 7),\n",
       " 23: (8, 7),\n",
       " 24: (4, 4),\n",
       " 25: (4, 4),\n",
       " 26: (1, 7),\n",
       " 27: (1, 7)}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into by Sex\n",
    "### Groups:\n",
    "- Male\n",
    "- Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list ={'sub-001_reward',\n",
    "'sub-015_reward',\n",
    "'sub-038_reward',\n",
    "'sub-045_reward',\n",
    "'sub-047_reward',\n",
    "'sub-048_reward',\n",
    "'sub-050_reward',\n",
    "'sub-056_reward',\n",
    "'sub-058_reward',\n",
    "'sub-060_reward',\n",
    "'sub-061_reward',\n",
    "'sub-062_reward',\n",
    "'sub-068_reward',\n",
    "'sub-075_reward',\n",
    "'sub-084_reward',\n",
    "'sub-085_reward',\n",
    "'sub-088_reward',\n",
    "'sub-022_reward',\n",
    "'sub-037_reward',\n",
    "'sub-043_reward',\n",
    "'sub-064_reward',\n",
    "'sub-079_reward',\n",
    "'sub-014_reward',\n",
    "'sub-016_reward',\n",
    "'sub-019_reward',\n",
    "'sub-053_reward',\n",
    "'sub-054_reward',\n",
    "'sub-055_reward',\n",
    "'sub-059_reward',\n",
    "'sub-074_reward',\n",
    "'sub-082_reward',\n",
    "'sub-044_reward',\n",
    "'sub-028_reward',\n",
    "'sub-033_reward',\n",
    "'sub-034_reward',\n",
    "'sub-035_reward',\n",
    "'sub-042_reward',\n",
    "'sub-046_reward',\n",
    "'sub-057_reward',\n",
    "'sub-076_reward',\n",
    "'sub-080_reward',\n",
    "'sub-090_reward',}\n",
    "f_list = {'sub-002_reward',\n",
    "'sub-004_reward',\n",
    "'sub-006_reward',\n",
    "'sub-009_reward',\n",
    "'sub-011_reward',\n",
    "'sub-017_reward',\n",
    "'sub-024_reward',\n",
    "'sub-026_reward',\n",
    "'sub-029_reward',\n",
    "'sub-031_reward',\n",
    "'sub-036_reward',\n",
    "'sub-069_reward',\n",
    "'sub-070_reward',\n",
    "'sub-073_reward',\n",
    "'sub-003_reward',\n",
    "'sub-010_reward',\n",
    "'sub-020_reward',\n",
    "'sub-013_reward',\n",
    "'sub-027_reward',\n",
    "'sub-041_reward',\n",
    "'sub-071_reward',\n",
    "'sub-086_reward',\n",
    "'sub-089_reward',\n",
    "'sub-012_reward',\n",
    "'sub-005_reward',\n",
    "'sub-007_reward',\n",
    "'sub-018_reward',\n",
    "'sub-021_reward',\n",
    "'sub-025_reward',\n",
    "'sub-030_reward',\n",
    "'sub-032_reward',\n",
    "'sub-040_reward',\n",
    "'sub-052_reward',\n",
    "'sub-066_reward',\n",
    "'sub-072_reward',\n",
    "'sub-087_reward',\n",
    "'sub-067_reward',\n",
    "'sub-083_reward',\n",
    "'sub-039_reward',\n",
    "'sub-063_reward',\n",
    "'sub-077_reward',\n",
    "'sub-078_reward',\n",
    "'sub-081_reward',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in m_list}\n",
    "f_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in f_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_m_graph = make_total_graphs(m_corr_dict)\n",
    "mean_f_graph = make_total_graphs(f_corr_dict)\n",
    "\n",
    "mean_m_graph_mat = np.matrix(mean_m_graph)\n",
    "mean_f_graph_mat = np.matrix(mean_f_graph)\n",
    "\n",
    "mean_m_G = nx.from_numpy_matrix(mean_m_graph_mat)\n",
    "mean_f_G = nx.from_numpy_matrix(mean_f_graph_mat)\n",
    "\n",
    "partition_m = community.best_partition(mean_m_G)\n",
    "nx.set_node_attributes(mean_m_G, partition_m, 'modules')\n",
    "nx.set_node_attributes(mean_m_G, labels_dict, 'ROIs')\n",
    "\n",
    "partition_f = community.best_partition(mean_f_G)\n",
    "nx.set_node_attributes(mean_f_G, partition_f, 'modules')\n",
    "nx.set_node_attributes(mean_f_G, labels_dict, 'ROIs')\n",
    "\n",
    "thresh_m_G = threshold(mean_m_G, 'positive', 0.3)\n",
    "thresh_f_G = threshold(mean_f_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_m_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_f_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [partition_m, partition_f]\n",
    "d = {}\n",
    "for k in partition_m.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (2, 2),\n",
       " 5: (3, 3),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (4, 4),\n",
       " 9: (4, 4),\n",
       " 10: (3, 3),\n",
       " 11: (3, 3),\n",
       " 12: (3, 5),\n",
       " 13: (3, 5),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (5, 6),\n",
       " 19: (5, 6),\n",
       " 20: (6, 0),\n",
       " 21: (6, 0),\n",
       " 22: (1, 7),\n",
       " 23: (1, 7),\n",
       " 24: (4, 4),\n",
       " 25: (4, 4),\n",
       " 26: (1, 7),\n",
       " 27: (1, 7)}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Normalized Mutual Information Scores\n",
    "\n",
    "Scores range from 0 to 1. Values increase as sets become more similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7180543446602383"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_HW_list = []\n",
    "for value in partition_HW.values():\n",
    "    partition_HW_list.append(partition_HW[value])\n",
    "\n",
    "partition_OB_list = []\n",
    "for value in partition_OB.values():\n",
    "    partition_OB_list.append(partition_OB[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_HW_list, partition_OB_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7735250658957238"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_l_list = []\n",
    "for value in partition_l.values():\n",
    "    partition_l_list.append(partition_l[value])\n",
    "\n",
    "partition_nl_list = []\n",
    "for value in partition_nl.values():\n",
    "    partition_nl_list.append(partition_nl[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_l_list, partition_nl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358726441483001"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_m_list = []\n",
    "for value in partition_m.values():\n",
    "    partition_m_list.append(partition_m[value])\n",
    "\n",
    "partition_f_list = []\n",
    "for value in partition_f.values():\n",
    "    partition_f_list.append(partition_f[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_m_list, partition_f_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response to PUNISH\n",
    "\n",
    "## Load in the data\n",
    "\n",
    "### Find the path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the path to data\n",
    "file_list = glob.glob(os.path.join(basepath,'betaseries_bevel/4_combine_timeseries/punishment/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting the ditionary\n",
    "my_dict={}\n",
    "for item in file_list:\n",
    "    name=item.split('/')[7].split('.')[0]\n",
    "    #print(name)\n",
    "    my_dict.setdefault(name, []).append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the data dictionary\n",
    "data_dict={}\n",
    "for key, value in my_dict.items():\n",
    "    for i in value:\n",
    "        data_dict.setdefault(key, []).append(pd.read_csv(i, sep='\\t' ,header=None,index_col=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the correlation dictionary\n",
    "cor_dict={}\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    value[0]\n",
    "    #pdb.set_trace()\n",
    "    cor_matrix = value[0].corr()\n",
    "    cor_dict[key] = cor_matrix   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply 'Make Graphs' function to correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "GRAPHS = make_graphs(cor_dict, \"positive\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into BMI Subsamples\n",
    "\n",
    "### Groups: \n",
    "- HW: BMI < 25.0\n",
    "- OB: BMI > 25.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_list = {'sub-001_punish',\n",
    "'sub-002_punish',\n",
    "'sub-004_punish',\n",
    "'sub-005_punish',\n",
    "'sub-006_punish',\n",
    "'sub-007_punish',\n",
    "'sub-009_punish',\n",
    "'sub-011_punish',\n",
    "'sub-014_punish',\n",
    "'sub-015_punish',\n",
    "'sub-016_punish',\n",
    "'sub-017_punish',\n",
    "'sub-018_punish',\n",
    "'sub-019_punish',\n",
    "'sub-021_punish',\n",
    "'sub-024_punish',\n",
    "'sub-025_punish',\n",
    "'sub-026_punish',\n",
    "'sub-029_punish',\n",
    "'sub-030_punish',\n",
    "'sub-031_punish',\n",
    "'sub-032_punish',\n",
    "'sub-036_punish',\n",
    "'sub-038_punish',\n",
    "'sub-040_punish',\n",
    "'sub-045_punish',\n",
    "'sub-047_punish',\n",
    "'sub-048_punish',\n",
    "'sub-050_punish',\n",
    "'sub-052_punish',\n",
    "'sub-053_punish',\n",
    "'sub-054_punish',\n",
    "'sub-055_punish',\n",
    "'sub-056_punish',\n",
    "'sub-058_punish',\n",
    "'sub-059_punish',\n",
    "'sub-060_punish',\n",
    "'sub-061_punish',\n",
    "'sub-062_punish',\n",
    "'sub-066_punish',\n",
    "'sub-068_punish',\n",
    "'sub-069_punish',\n",
    "'sub-070_punish',\n",
    "'sub-072_punish',\n",
    "'sub-073_punish',\n",
    "'sub-074_punish',\n",
    "'sub-075_punish',\n",
    "'sub-082_punish',\n",
    "'sub-084_punish',\n",
    "'sub-085_punish',\n",
    "'sub-087_punish',\n",
    "'sub-088_punish',}\n",
    "\n",
    "ob_list = {'sub-003_punish',\n",
    "'sub-010_punish',\n",
    "'sub-020_punish',\n",
    "'sub-022_punish',\n",
    "'sub-044_punish',\n",
    "'sub-067_punish',\n",
    "'sub-083_punish',\n",
    "'sub-012_punish',\n",
    "'sub-013_punish',\n",
    "'sub-027_punish',\n",
    "'sub-028_punish',\n",
    "'sub-033_punish',\n",
    "'sub-034_punish',\n",
    "'sub-035_punish',\n",
    "'sub-037_punish',\n",
    "'sub-039_punish',\n",
    "'sub-041_punish',\n",
    "'sub-042_punish',\n",
    "'sub-043_punish',\n",
    "'sub-046_punish',\n",
    "'sub-057_punish',\n",
    "'sub-063_punish',\n",
    "'sub-064_punish',\n",
    "'sub-071_punish',\n",
    "'sub-076_punish',\n",
    "'sub-077_punish',\n",
    "'sub-078_punish',\n",
    "'sub-079_punish',\n",
    "'sub-080_punish',\n",
    "'sub-081_punish',\n",
    "'sub-086_punish',\n",
    "'sub-089_punish',\n",
    "'sub-090_punish',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in hw_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in ob_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine participant correlation matrices into one mean correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make the mean graph with correlations\n",
    "mean_hw_graph = make_total_graphs(hw_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ob_graph = make_total_graphs(ob_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2920281362012932"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to make sure this worked \n",
    "print(mean_hw_graph.shape)\n",
    "\n",
    "#Convert the graph to a numpy matrix so it can be recognized by networkX\n",
    "mean_hw_graph_mat = np.matrix(mean_hw_graph)\n",
    "\n",
    "#Check the mean correlation to use to threshold later\n",
    "mean_hw_graph_mat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ob_graph_mat = np.matrix(mean_ob_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_HW_G = nx.from_numpy_matrix(mean_hw_graph_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_OB_G = nx.from_numpy_matrix(mean_ob_graph_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Modularity in the Mean Graph for HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_HW = community.best_partition(mean_HW_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the modules and ROI labels to the graph\n",
    "nx.set_node_attributes(mean_HW_G, partition_HW, 'modules')\n",
    "nx.set_node_attributes(mean_HW_G, labels_dict, 'ROIs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Modularity in the Mean Graph for OB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_OB = community.best_partition(mean_OB_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(mean_OB_G, partition_OB, 'modules')\n",
    "nx.set_node_attributes(mean_OB_G, labels_dict, 'ROIs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to make a thresholded graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_HW_G = threshold(mean_HW_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_OB_G = threshold(mean_OB_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to visualize thresholded graph with modules in colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_HW_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_OB_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = [partition_HW, partition_OB]\n",
    "d = {}\n",
    "for k in partition_HW.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (2, 2),\n",
       " 5: (3, 2),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (4, 3),\n",
       " 9: (4, 3),\n",
       " 10: (3, 2),\n",
       " 11: (3, 2),\n",
       " 12: (5, 4),\n",
       " 13: (5, 4),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (6, 5),\n",
       " 19: (6, 5),\n",
       " 20: (7, 6),\n",
       " 21: (7, 6),\n",
       " 22: (8, 7),\n",
       " 23: (8, 7),\n",
       " 24: (4, 3),\n",
       " 25: (4, 3),\n",
       " 26: (1, 7),\n",
       " 27: (1, 7)}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into Learner Subsamples\n",
    "### Groups:\n",
    "- Learner: overall posttest accuracy > 50%\n",
    "- Nonlearner: overall posttest accuracy < 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_list = {'sub-001_punish',\n",
    "'sub-002_punish',\n",
    "'sub-004_punish',\n",
    "'sub-006_punish',\n",
    "'sub-009_punish',\n",
    "'sub-011_punish',\n",
    "'sub-015_punish',\n",
    "'sub-017_punish',\n",
    "'sub-024_punish',\n",
    "'sub-026_punish',\n",
    "'sub-029_punish',\n",
    "'sub-031_punish',\n",
    "'sub-036_punish',\n",
    "'sub-038_punish',\n",
    "'sub-045_punish',\n",
    "'sub-047_punish',\n",
    "'sub-048_punish',\n",
    "'sub-050_punish',\n",
    "'sub-056_punish',\n",
    "'sub-058_punish',\n",
    "'sub-060_punish',\n",
    "'sub-061_punish',\n",
    "'sub-062_punish',\n",
    "'sub-068_punish',\n",
    "'sub-069_punish',\n",
    "'sub-070_punish',\n",
    "'sub-073_punish',\n",
    "'sub-075_punish',\n",
    "'sub-084_punish',\n",
    "'sub-085_punish',\n",
    "'sub-088_punish',\n",
    "'sub-003_punish',\n",
    "'sub-010_punish',\n",
    "'sub-020_punish',\n",
    "'sub-022_punish',\n",
    "'sub-013_punish',\n",
    "'sub-027_punish',\n",
    "'sub-037_punish',\n",
    "'sub-041_punish',\n",
    "'sub-043_punish',\n",
    "'sub-064_punish',\n",
    "'sub-071_punish',\n",
    "'sub-079_punish',\n",
    "'sub-086_punish',\n",
    "'sub-089_punish',}\n",
    "\n",
    "nolearn_list = {'sub-005_punish',\n",
    "'sub-007_punish',\n",
    "'sub-014_punish',\n",
    "'sub-016_punish',\n",
    "'sub-018_punish',\n",
    "'sub-019_punish',\n",
    "'sub-021_punish',\n",
    "'sub-025_punish',\n",
    "'sub-030_punish',\n",
    "'sub-032_punish',\n",
    "'sub-040_punish',\n",
    "'sub-052_punish',\n",
    "'sub-053_punish',\n",
    "'sub-054_punish',\n",
    "'sub-055_punish',\n",
    "'sub-059_punish',\n",
    "'sub-066_punish',\n",
    "'sub-072_punish',\n",
    "'sub-074_punish',\n",
    "'sub-082_punish',\n",
    "'sub-087_punish',\n",
    "'sub-044_punish',\n",
    "'sub-067_punish',\n",
    "'sub-083_punish',\n",
    "'sub-028_punish',\n",
    "'sub-033_punish',\n",
    "'sub-034_punish',\n",
    "'sub-035_punish',\n",
    "'sub-039_punish',\n",
    "'sub-042_punish',\n",
    "'sub-046_punish',\n",
    "'sub-057_punish',\n",
    "'sub-063_punish',\n",
    "'sub-076_punish',\n",
    "'sub-077_punish',\n",
    "'sub-078_punish',\n",
    "'sub-080_punish',\n",
    "'sub-081_punish',\n",
    "'sub-090_punish',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in learn_list}\n",
    "nolearn_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in nolearn_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_learn_graph = make_total_graphs(learn_corr_dict)\n",
    "mean_nolearn_graph = make_total_graphs(nolearn_corr_dict)\n",
    "\n",
    "mean_learn_graph_mat = np.matrix(mean_learn_graph)\n",
    "mean_nolearn_graph_mat = np.matrix(mean_nolearn_graph)\n",
    "\n",
    "mean_learn_G = nx.from_numpy_matrix(mean_learn_graph_mat)\n",
    "mean_nolearn_G = nx.from_numpy_matrix(mean_nolearn_graph_mat)\n",
    "\n",
    "partition_l = community.best_partition(mean_learn_G)\n",
    "nx.set_node_attributes(mean_learn_G, partition_l, 'modules')\n",
    "nx.set_node_attributes(mean_learn_G, labels_dict, 'ROIs')\n",
    "\n",
    "partition_nl = community.best_partition(mean_nolearn_G)\n",
    "nx.set_node_attributes(mean_nolearn_G, partition_nl, 'modules')\n",
    "nx.set_node_attributes(mean_nolearn_G, labels_dict, 'ROIs')\n",
    "\n",
    "thresh_learn_G = threshold(mean_learn_G, 'positive', 0.3)\n",
    "thresh_nolearn_G = threshold(mean_nolearn_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_learn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_nolearn_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [partition_l, partition_nl]\n",
    "d = {}\n",
    "for k in partition_l.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (2, 2),\n",
       " 5: (3, 3),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (4, 4),\n",
       " 9: (4, 4),\n",
       " 10: (3, 3),\n",
       " 11: (3, 3),\n",
       " 12: (5, 3),\n",
       " 13: (5, 3),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (6, 5),\n",
       " 19: (6, 5),\n",
       " 20: (7, 6),\n",
       " 21: (7, 6),\n",
       " 22: (8, 7),\n",
       " 23: (8, 7),\n",
       " 24: (4, 4),\n",
       " 25: (4, 4),\n",
       " 26: (1, 7),\n",
       " 27: (1, 7)}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split GRAPHS dictionary into by Sex\n",
    "### Groups:\n",
    "- Male\n",
    "- Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list ={'sub-001_punish',\n",
    "'sub-015_punish',\n",
    "'sub-038_punish',\n",
    "'sub-045_punish',\n",
    "'sub-047_punish',\n",
    "'sub-048_punish',\n",
    "'sub-050_punish',\n",
    "'sub-056_punish',\n",
    "'sub-058_punish',\n",
    "'sub-060_punish',\n",
    "'sub-061_punish',\n",
    "'sub-062_punish',\n",
    "'sub-068_punish',\n",
    "'sub-075_punish',\n",
    "'sub-084_punish',\n",
    "'sub-085_punish',\n",
    "'sub-088_punish',\n",
    "'sub-022_punish',\n",
    "'sub-037_punish',\n",
    "'sub-043_punish',\n",
    "'sub-064_punish',\n",
    "'sub-079_punish',\n",
    "'sub-014_punish',\n",
    "'sub-016_punish',\n",
    "'sub-019_punish',\n",
    "'sub-053_punish',\n",
    "'sub-054_punish',\n",
    "'sub-055_punish',\n",
    "'sub-059_punish',\n",
    "'sub-074_punish',\n",
    "'sub-082_punish',\n",
    "'sub-044_punish',\n",
    "'sub-028_punish',\n",
    "'sub-033_punish',\n",
    "'sub-034_punish',\n",
    "'sub-035_punish',\n",
    "'sub-042_punish',\n",
    "'sub-046_punish',\n",
    "'sub-057_punish',\n",
    "'sub-076_punish',\n",
    "'sub-080_punish',\n",
    "'sub-090_punish',}\n",
    "f_list = {'sub-002_punish',\n",
    "'sub-004_punish',\n",
    "'sub-006_punish',\n",
    "'sub-009_punish',\n",
    "'sub-011_punish',\n",
    "'sub-017_punish',\n",
    "'sub-024_punish',\n",
    "'sub-026_punish',\n",
    "'sub-029_punish',\n",
    "'sub-031_punish',\n",
    "'sub-036_punish',\n",
    "'sub-069_punish',\n",
    "'sub-070_punish',\n",
    "'sub-073_punish',\n",
    "'sub-003_punish',\n",
    "'sub-010_punish',\n",
    "'sub-020_punish',\n",
    "'sub-013_punish',\n",
    "'sub-027_punish',\n",
    "'sub-041_punish',\n",
    "'sub-071_punish',\n",
    "'sub-086_punish',\n",
    "'sub-089_punish',\n",
    "'sub-012_punish',\n",
    "'sub-005_punish',\n",
    "'sub-007_punish',\n",
    "'sub-018_punish',\n",
    "'sub-021_punish',\n",
    "'sub-025_punish',\n",
    "'sub-030_punish',\n",
    "'sub-032_punish',\n",
    "'sub-040_punish',\n",
    "'sub-052_punish',\n",
    "'sub-066_punish',\n",
    "'sub-072_punish',\n",
    "'sub-087_punish',\n",
    "'sub-067_punish',\n",
    "'sub-083_punish',\n",
    "'sub-039_punish',\n",
    "'sub-063_punish',\n",
    "'sub-077_punish',\n",
    "'sub-078_punish',\n",
    "'sub-081_punish',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in m_list}\n",
    "f_corr_dict = { key:value for key,value in GRAPHS['correlations'].items() if key in f_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_m_graph = make_total_graphs(m_corr_dict)\n",
    "mean_f_graph = make_total_graphs(f_corr_dict)\n",
    "\n",
    "mean_m_graph_mat = np.matrix(mean_m_graph)\n",
    "mean_f_graph_mat = np.matrix(mean_f_graph)\n",
    "\n",
    "mean_m_G = nx.from_numpy_matrix(mean_m_graph_mat)\n",
    "mean_f_G = nx.from_numpy_matrix(mean_f_graph_mat)\n",
    "\n",
    "partition_m = community.best_partition(mean_m_G)\n",
    "nx.set_node_attributes(mean_m_G, partition_m, 'modules')\n",
    "nx.set_node_attributes(mean_m_G, labels_dict, 'ROIs')\n",
    "\n",
    "partition_f = community.best_partition(mean_f_G)\n",
    "nx.set_node_attributes(mean_f_G, partition_f, 'modules')\n",
    "nx.set_node_attributes(mean_f_G, labels_dict, 'ROIs')\n",
    "\n",
    "thresh_m_G = threshold(mean_m_G, 'positive', 0.3)\n",
    "thresh_f_G = threshold(mean_f_G, 'positive', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_m_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jenny_graph(thresh_f_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [partition_m, partition_f]\n",
    "d = {}\n",
    "for k in partition_m.keys():\n",
    "  d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 0),\n",
       " 1: (0, 0),\n",
       " 2: (1, 1),\n",
       " 3: (1, 1),\n",
       " 4: (2, 2),\n",
       " 5: (3, 2),\n",
       " 6: (0, 0),\n",
       " 7: (0, 0),\n",
       " 8: (4, 3),\n",
       " 9: (4, 3),\n",
       " 10: (3, 2),\n",
       " 11: (3, 2),\n",
       " 12: (3, 4),\n",
       " 13: (3, 4),\n",
       " 14: (2, 2),\n",
       " 15: (2, 2),\n",
       " 16: (1, 1),\n",
       " 17: (1, 1),\n",
       " 18: (5, 5),\n",
       " 19: (5, 5),\n",
       " 20: (6, 0),\n",
       " 21: (6, 0),\n",
       " 22: (1, 6),\n",
       " 23: (1, 6),\n",
       " 24: (4, 3),\n",
       " 25: (4, 3),\n",
       " 26: (1, 6),\n",
       " 27: (1, 6)}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMI Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6848308134347534"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_HW_list = []\n",
    "for value in partition_HW.values():\n",
    "    partition_HW_list.append(partition_HW[value])\n",
    "\n",
    "partition_OB_list = []\n",
    "for value in partition_OB.values():\n",
    "    partition_OB_list.append(partition_OB[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_HW_list, partition_OB_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7735250658957238"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_l_list = []\n",
    "for value in partition_l.values():\n",
    "    partition_l_list.append(partition_l[value])\n",
    "\n",
    "partition_nl_list = []\n",
    "for value in partition_nl.values():\n",
    "    partition_nl_list.append(partition_nl[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_l_list, partition_nl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7714836723402282"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_m_list = []\n",
    "for value in partition_m.values():\n",
    "    partition_m_list.append(partition_m[value])\n",
    "\n",
    "partition_f_list = []\n",
    "for value in partition_f.values():\n",
    "    partition_f_list.append(partition_f[value])\n",
    "\n",
    "    \n",
    "normalized_mutual_info_score(partition_m_list, partition_f_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save GRAPHS dictionary in a pickle file in case of crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(GRAPHS, open(os.path.join(basepath, 'betaseries_bevel/tmp/Graphs'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(basepath, 'betaseries_bevel/tmp/Graphs'), 'rb') as pickle_file:\n",
    "    try:\n",
    "        while True:\n",
    "            GRAPHS = pickle.load(pickle_file)\n",
    "#             print (GRAPHS)\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
